apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: cilium
  namespace: kube-system
spec:
  interval: 30m
  timeout: 10m
  chart:
    spec:
      chart: cilium
      version: "1.19.0"  # Latest stable - works with K3s when properly configured
      sourceRef:
        kind: HelmRepository
        name: cilium
        namespace: kube-system
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    remediation:
      retries: 3
  values:
    # Clean up leftover Cilium state from previous installation attempts
    # TODO: Set to false after all nodes are healthy
    cleanState: true

    # K3s specific configuration
    # Use control plane IP explicitly (required for K3s worker nodes)
    k8sServiceHost: "10.85.30.214"
    k8sServicePort: "6443"

    # K3s compatibility: keep kube-proxy (don't replace it during migration)
    kubeProxyReplacement: false

    # K3s client rate limits (prevents API server throttling)
    k8sClientRateLimit:
      qps: 50
      burst: 200

    # CNI Configuration for K3s migration from Flannel
    cni:
      exclusive: false  # Don't remove other CNI configs during migration
      # Note: chainingMode removed - generic-veth deprecated in 1.19.0
      # Cilium will write its own CNI config without chaining

    # IPAM Configuration - use K3s default CIDR
    ipam:
      mode: cluster-pool
      operator:
        clusterPoolIPv4PodCIDRList:
          - "10.42.0.0/16"

    # Policy Enforcement - AUDIT MODE (Phase 1)
    # Change to "default" in Phase 3 after node migration
    policyEnforcementMode: "never"
    policyAuditMode: true

    # Tunnel Configuration - use Geneve to avoid VXLAN device conflict
    # Flannel uses vxlan, so we use geneve to avoid 'address already in use' error
    routingMode: tunnel
    tunnelProtocol: geneve
    tunnelPort: 6081  # Geneve default port

    # BPF Configuration
    # Enable masquerading for pod egress to external networks
    bpf:
      masquerade: true

    # Operator Configuration
    operator:
      replicas: 1
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 128Mi

    # Agent Resources
    resources:
      limits:
        cpu: 1000m
        memory: 1Gi
      requests:
        cpu: 300m
        memory: 512Mi

    # Hubble Observability
    hubble:
      enabled: true
      relay:
        enabled: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
      ui:
        enabled: true
        replicas: 1
        ingress:
          enabled: true
          className: traefik
          annotations:
            cert-manager.io/cluster-issuer: letsencrypt-production
          hosts:
            - hubble.landryzetam.net
          tls:
            - secretName: hubble-tls-cert
              hosts:
                - hubble.landryzetam.net
        resources:
          limits:
            cpu: 500m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
      metrics:
        enabled:
          - dns
          - drop
          - tcp
          - flow
          - icmp
          - http
        serviceMonitor:
          enabled: true

    # Prometheus Integration
    prometheus:
      enabled: true
      serviceMonitor:
        enabled: true

    # Security Context
    securityContext:
      privileged: true  # Required for eBPF
