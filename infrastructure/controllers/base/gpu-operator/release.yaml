# infrastructure/controllers/base/gpu-operator/release.yaml
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: gpu-operator
  namespace: gpu-operator
spec:
  interval: 30m
  timeout: 10m
  chart:
    spec:
      chart: gpu-operator
      version: "v24.9.1"
      sourceRef:
        kind: HelmRepository
        name: nvidia
        namespace: gpu-operator
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    remediation:
      retries: 3
  values:
    # Since drivers are already installed, disable driver container
    driver:
      enabled: false
      
    # Container toolkit configuration
    toolkit:
      enabled: true
      version: v1.17.3
      repository: nvcr.io/nvidia
      image: container-toolkit
      tag: v1.17.3-ubi8
      
    # Device plugin configuration
    devicePlugin:
      enabled: true
      version: v0.17.2
      repository: nvcr.io/nvidia
      image: k8s-device-plugin
      tag: v0.17.2
      
    # Disable optional components for now
    nfd:
      enabled: false
    gfd:
      enabled: false
    dcgm:
      enabled: false
    dcgmExporter:
      enabled: false
    migManager:
      enabled: false
      
    # Validator configuration
    validator:
      repository: nvcr.io/nvidia/cloud-native
      image: gpu-operator-validator
      version: v24.9.1
      plugin:
        env:
        - name: WITH_WORKLOAD
          value: "false"
          
    # Operator configuration
    operator:
      defaultRuntime: containerd
      repository: nvcr.io/nvidia
      image: gpu-operator
      tag: v24.9.1
      
    daemonsets:
      updateStrategy: "RollingUpdate"  # Just the string value
      priorityClassName: system-node-critical
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule