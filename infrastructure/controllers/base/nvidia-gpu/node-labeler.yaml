# infrastructure/controllers/base/nvidia-gpu/node-labeler-updated.yaml
# This is an updated version of the node-labeler.yaml that provides more comprehensive
# GPU node detection and labeling capabilities

apiVersion: v1
kind: ServiceAccount
metadata:
  name: nvidia-node-labeler
  namespace: nvidia-device-plugin
  labels:
    app.kubernetes.io/name: nvidia-node-labeler
    app.kubernetes.io/part-of: nvidia-gpu-infrastructure
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nvidia-node-labeler
  labels:
    app.kubernetes.io/name: nvidia-node-labeler
    app.kubernetes.io/part-of: nvidia-gpu-infrastructure
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "patch", "update"]
- apiGroups: [""]
  resources: ["nodes/status"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nvidia-node-labeler
  labels:
    app.kubernetes.io/name: nvidia-node-labeler
    app.kubernetes.io/part-of: nvidia-gpu-infrastructure
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nvidia-node-labeler
subjects:
- kind: ServiceAccount
  name: nvidia-node-labeler
  namespace: nvidia-device-plugin
---
apiVersion: batch/v1
kind: Job
metadata:
  name: label-nvidia-gpu-nodes
  namespace: nvidia-device-plugin
  labels:
    app.kubernetes.io/name: nvidia-node-labeler
    app.kubernetes.io/part-of: nvidia-gpu-infrastructure
  annotations:
    description: "Labels nodes with NVIDIA GPUs for device plugin deployment"
spec:
  # Clean up after 5 minutes
  ttlSecondsAfterFinished: 300
  
  # Retry up to 3 times
  backoffLimit: 3
  
  # Job timeout
  activeDeadlineSeconds: 600
  
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nvidia-node-labeler
        app.kubernetes.io/part-of: nvidia-gpu-infrastructure
    spec:
      serviceAccountName: nvidia-node-labeler
      restartPolicy: OnFailure
      
      # Run on control plane to avoid GPU node issues
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
      tolerations:
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
        
      containers:
      - name: labeler
        image: bitnami/kubectl:1.29
        imagePullPolicy: IfNotPresent
        
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
            
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -e
          
          echo "=== NVIDIA GPU Node Labeling Job ==="
          echo "Date: $(date)"
          echo ""
          
          # Function to label a node
          label_node() {
            local node=$1
            echo "Labeling node: $node"
            
            # Apply all GPU-related labels
            kubectl label nodes "$node" nvidia.com/gpu=true --overwrite
            kubectl label nodes "$node" accelerator=nvidia-gpu --overwrite
            kubectl label nodes "$node" gpu.nvidia.present=true --overwrite
            kubectl label nodes "$node" feature.node.kubernetes.io/pci-10de.present=true --overwrite
            kubectl label nodes "$node" node-role.kubernetes.io/gpu-worker=true --overwrite
            kubectl label nodes "$node" hardware.tier=gpu --overwrite
            
            echo "✓ Labels applied to $node"
          }
          
          # Get current nodes
          echo "Current cluster nodes:"
          kubectl get nodes -o wide
          echo ""
          
          # Label playground node (from your config)
          if kubectl get node playground > /dev/null 2>&1; then
            echo "Found playground node - applying GPU labels..."
            label_node playground
          else
            echo "WARNING: playground node not found!"
          fi
          
          # Check pgbee node and remove old labels if needed
          if kubectl get node pgbee > /dev/null 2>&1; then
            echo "Found pgbee node - removing any old GPU labels..."
            kubectl label nodes pgbee node-role.kubernetes.io/gpu-worker- --overwrite 2>/dev/null || true
            echo "✓ Cleaned pgbee node"
          fi
          
          # Final verification
          echo ""
          echo "=== Verification ==="
          echo "GPU-labeled nodes:"
          kubectl get nodes -l nvidia.com/gpu=true --show-labels | grep -E "(nvidia|gpu)" || echo "No GPU labels found"
          
          echo ""
          echo "=== Job completed successfully ==="