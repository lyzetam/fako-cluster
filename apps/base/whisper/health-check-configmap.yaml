# apps/base/whisper/health-check-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: whisper-gpu-health
  namespace: whisper
data:
  health-check.py: |
    #!/usr/bin/env python3
    import sys
    import torch
    import subprocess
    
    def check_gpu():
        print("=== GPU Health Check ===")
        
        # Check CUDA availability
        if not torch.cuda.is_available():
            print("❌ CUDA is not available")
            return False
        
        print(f"✅ CUDA is available")
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   PyTorch version: {torch.__version__}")
        
        # Check GPU count
        gpu_count = torch.cuda.device_count()
        print(f"✅ Found {gpu_count} GPU(s)")
        
        # Check each GPU
        for i in range(gpu_count):
            print(f"\n   GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"   Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
        
        # Test GPU computation
        try:
            x = torch.rand(1000, 1000).cuda()
            y = torch.rand(1000, 1000).cuda()
            z = torch.matmul(x, y)
            torch.cuda.synchronize()
            print("\n✅ GPU computation test passed")
        except Exception as e:
            print(f"\n❌ GPU computation test failed: {e}")
            return False
        
        # Check nvidia-smi
        try:
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
            if result.returncode == 0:
                print("\n✅ nvidia-smi is working")
            else:
                print("\n❌ nvidia-smi failed")
                return False
        except:
            print("\n❌ nvidia-smi not found")
            return False
        
        return True
    
    if __name__ == "__main__":
        if check_gpu():
            print("\n✅ All GPU checks passed!")
            sys.exit(0)
        else:
            print("\n❌ GPU checks failed!")
            sys.exit(1)