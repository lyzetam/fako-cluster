apiVersion: v1
kind: ConfigMap
metadata:
  name: voice-pipeline-test-source
  namespace: voice-pipeline-test
data:
  app.py: |
    #!/usr/bin/env python3
    """
    Voice Pipeline Test Flask Application
    Provides HTTP endpoints for testing voice pipeline components
    """
    
    from flask import Flask, jsonify, request
    import os
    import time
    import logging
    from datetime import datetime
    from test_runner import VoicePipelineTest
    
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    # Initialize Flask app
    app = Flask(__name__)
    
    # Configuration from environment
    CONFIG = {
        'whisper_endpoint': os.getenv('WHISPER_ENDPOINT', 'http://whisper-nodeport.whisper:10300'),
        'ollama_endpoint': os.getenv('OLLAMA_ENDPOINT', 'http://ollama-gpu.ollama:11434'),
        'piper_endpoint': os.getenv('PIPER_ENDPOINT', 'http://piper-nodeport.piper:10200'),
        'ollama_model': os.getenv('OLLAMA_MODEL', 'qwen3:8b'),
        'audio_file_path': os.getenv('AUDIO_FILE_PATH', '/audio-data/test-audio.wav')
    }
    
    # Initialize test runner
    test_runner = VoicePipelineTest(CONFIG)
    
    @app.route('/health', methods=['GET'])
    def health():
        """Health check endpoint"""
        return jsonify({
            'status': 'healthy',
            'timestamp': datetime.now().isoformat()
        }), 200
    
    @app.route('/ready', methods=['GET'])
    def ready():
        """Readiness check endpoint"""
        # Check if audio file exists
        if not os.path.exists(CONFIG['audio_file_path']):
            return jsonify({
                'status': 'not ready',
                'reason': 'Audio file not found',
                'timestamp': datetime.now().isoformat()
            }), 503
        
        return jsonify({
            'status': 'ready',
            'timestamp': datetime.now().isoformat()
        }), 200
    
    @app.route('/config', methods=['GET'])
    def get_config():
        """Return current configuration"""
        return jsonify(CONFIG), 200
    
    @app.route('/test', methods=['POST'])
    def run_test():
        """Run the voice pipeline test"""
        logger.info("Starting voice pipeline test")
        
        try:
            # Get optional parameters from request
            data = request.get_json() or {}
            timeout = data.get('timeout', 60)
            
            # Run the test
            results = test_runner.run_pipeline_test(timeout=timeout)
            
            logger.info(f"Test completed: {results.get('total_ms', 0):.2f}ms total")
            
            # Check for errors
            has_errors = any(key.endswith('_error') for key in results.keys())
            status_code = 200 if not has_errors else 207  # 207 = Multi-Status
            
            return jsonify({
                'success': not has_errors,
                'results': results,
                'timestamp': datetime.now().isoformat()
            }), status_code
            
        except Exception as e:
            logger.error(f"Test failed: {str(e)}")
            return jsonify({
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }), 500
    
    @app.route('/test/summary', methods=['GET'])
    def get_last_summary():
        """Get summary of last test run"""
        last_results = test_runner.get_last_results()
        if last_results:
            return jsonify(last_results), 200
        return jsonify({'message': 'No test results available'}), 404
    
    @app.route('/metrics', methods=['GET'])
    def metrics():
        """Prometheus-compatible metrics endpoint"""
        metrics_text = test_runner.get_prometheus_metrics()
        return metrics_text, 200, {'Content-Type': 'text/plain'}
    
    if __name__ == '__main__':
        port = int(os.getenv('PORT', 8080))
        app.run(host='0.0.0.0', port=port)
  
  test_runner.py: |
    #!/usr/bin/env python3
    """
    Voice Pipeline Test Runner
    Handles the actual testing logic for voice pipeline components
    """
    
    import requests
    import time
    import os
    import json
    import logging
    from datetime import datetime
    from typing import Dict, Any, Optional
    
    logger = logging.getLogger(__name__)
    
    class VoicePipelineTest:
        def __init__(self, config: Dict[str, str]):
            self.config = config
            self.last_results = None
            
        def run_pipeline_test(self, timeout: int = 60) -> Dict[str, Any]:
            """Run the complete voice pipeline test"""
            
            logger.info("="*70)
            logger.info(f"Voice Pipeline Test - {datetime.now()}")
            logger.info("="*70)
            
            results = {
                'timestamp': datetime.now().isoformat(),
                'config': self.config
            }
            pipeline_start = time.time()
            
            # Load audio file
            try:
                with open(self.config['audio_file_path'], 'rb') as f:
                    audio_data = f.read()
                logger.info(f"✓ Loaded audio file: {len(audio_data)} bytes")
                results['audio_size'] = len(audio_data)
            except Exception as e:
                logger.error(f"✗ Failed to load audio: {e}")
                results['audio_error'] = str(e)
                return results
            
            # Stage 1: Simulate openwakeword detection
            logger.info("[1/5] Simulating wake word detection...")
            stage_start = time.time()
            time.sleep(0.05)  # Simulate detection processing
            results['openwakeword_ms'] = (time.time() - stage_start) * 1000
            logger.info(f"      Duration: {results['openwakeword_ms']:.2f}ms")
            
            # Stage 2: Test HTTP connectivity to services
            logger.info("[2/5] Testing HTTP connectivity...")
            connectivity_results = {}
            
            # Test Whisper HTTP
            try:
                start = time.time()
                resp = requests.get(f"{self.config['whisper_endpoint']}/", timeout=2)
                connectivity_results['whisper_http'] = {
                    'status': resp.status_code,
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Whisper HTTP: {resp.status_code} ({connectivity_results['whisper_http']['latency_ms']:.2f}ms)")
            except Exception as e:
                connectivity_results['whisper_http'] = {
                    'error': str(e)[:100],
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Whisper HTTP: Failed ({connectivity_results['whisper_http']['latency_ms']:.2f}ms)")
            
            # Test Ollama HTTP
            try:
                start = time.time()
                resp = requests.get(f"{self.config['ollama_endpoint']}/", timeout=2)
                connectivity_results['ollama_http'] = {
                    'status': resp.status_code,
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Ollama HTTP: {resp.status_code} ({connectivity_results['ollama_http']['latency_ms']:.2f}ms)")
            except Exception as e:
                connectivity_results['ollama_http'] = {
                    'error': str(e)[:100],
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Ollama HTTP: Failed ({connectivity_results['ollama_http']['latency_ms']:.2f}ms)")
            
            # Test Piper TCP (Wyoming protocol)
            try:
                import socket
                start = time.time()
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(2)
                # Extract host and port from endpoint
                host = self.config['piper_endpoint'].replace('http://', '').split(':')[0]
                port = 10200
                result = sock.connect_ex((host, port))
                sock.close()
                connectivity_results['piper_tcp'] = {
                    'connected': result == 0,
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Piper TCP: {'Connected' if result == 0 else 'Failed'} ({connectivity_results['piper_tcp']['latency_ms']:.2f}ms)")
            except Exception as e:
                connectivity_results['piper_tcp'] = {
                    'error': str(e)[:100],
                    'latency_ms': (time.time() - start) * 1000
                }
                logger.info(f"      Piper TCP: Failed ({connectivity_results['piper_tcp']['latency_ms']:.2f}ms)")
            
            results['connectivity'] = connectivity_results
            
            # Stage 3: Whisper transcription
            logger.info("[3/5] Calling Whisper for transcription...")
            stage_start = time.time()
            try:
                response = requests.post(
                    f"{self.config['whisper_endpoint']}/transcribe",
                    data=audio_data,
                    headers={'Content-Type': 'audio/wav'},
                    timeout=timeout
                )
                results['whisper_ms'] = (time.time() - stage_start) * 1000
                results['whisper_status'] = response.status_code
                
                # Try to extract text from response
                try:
                    response_data = response.json()
                    results['transcribed_text'] = response_data.get('text', response.text[:200])
                except:
                    results['transcribed_text'] = response.text[:200] if response.text else "No text"
                
                logger.info(f"      Status: {response.status_code}")
                logger.info(f"      Duration: {results['whisper_ms']:.2f}ms")
                logger.info(f"      Text: {results['transcribed_text'][:100]}...")
                
            except Exception as e:
                results['whisper_ms'] = (time.time() - stage_start) * 1000
                results['whisper_error'] = str(e)
                results['transcribed_text'] = "ERROR"
                logger.error(f"      ERROR: {e}")
            
            # Stage 4: Ollama inference
            logger.info("[4/5] Calling Ollama for LLM inference...")
            stage_start = time.time()
            try:
                # Use transcribed text or fallback
                prompt = results.get('transcribed_text', 'What is the weather like today?')
                if prompt == "ERROR" or not prompt:
                    prompt = "Hello, how can I help you?"
                
                response = requests.post(
                    f"{self.config['ollama_endpoint']}/api/generate",
                    json={
                        'model': self.config['ollama_model'],
                        'prompt': prompt,
                        'stream': False,
                        'options': {
                            'temperature': 0.7,
                            'max_tokens': 100
                        }
                    },
                    timeout=timeout
                )
                results['ollama_ms'] = (time.time() - stage_start) * 1000
                results['ollama_status'] = response.status_code
                
                try:
                    response_data = response.json()
                    results['llm_response'] = response_data.get('response', response.text[:200])
                except:
                    results['llm_response'] = response.text[:200] if response.text else "No response"
                
                logger.info(f"      Status: {response.status_code}")
                logger.info(f"      Duration: {results['ollama_ms']:.2f}ms")
                # Log full Ollama response for visibility
                logger.info(f"      Response preview: {results['llm_response'][:200]}...")
                logger.info("      Full Ollama Response:")
                for line in results['llm_response'].split('\n'):
                    if line.strip():
                        logger.info(f"        {line}")
                
            except Exception as e:
                results['ollama_ms'] = (time.time() - stage_start) * 1000
                results['ollama_error'] = str(e)
                results['llm_response'] = "ERROR"
                logger.error(f"      ERROR: {e}")
            
            # Stage 5: Piper TTS (Note: Piper uses Wyoming protocol, not REST API)
            logger.info("[5/5] Testing Piper TTS connectivity...")
            stage_start = time.time()
            try:
                # Use LLM response or fallback
                text_to_speak = results.get('llm_response', 'Test text for speech synthesis')
                if text_to_speak == "ERROR" or not text_to_speak:
                    text_to_speak = "Hello from the voice pipeline test"
                
                # For now, just test connectivity. Piper uses Wyoming protocol, not HTTP
                # This will timeout as expected since Piper doesn't respond to HTTP
                try:
                    response = requests.get(
                        f"{self.config['piper_endpoint']}/",
                        timeout=2  # Short timeout since we expect this to fail
                    )
                    results['piper_status'] = response.status_code
                except:
                    # Expected - Piper uses Wyoming protocol
                    results['piper_note'] = "Piper uses Wyoming protocol (TCP), not HTTP REST"
                
                results['piper_ms'] = (time.time() - stage_start) * 1000
                results['tts_text'] = text_to_speak[:200]  # Store what would be synthesized
                
                logger.info(f"      Duration: {results['piper_ms']:.2f}ms")
                logger.info(f"      Note: Piper uses Wyoming protocol, not HTTP")
                logger.info(f"      TTS Text preview: {results['tts_text'][:200]}...")
                
            except Exception as e:
                results['piper_ms'] = (time.time() - stage_start) * 1000
                results['piper_error'] = str(e)
                logger.error(f"      ERROR: {e}")
            
            # Calculate total
            results['total_ms'] = (time.time() - pipeline_start) * 1000
            
            # Print summary with both ms and seconds
            logger.info("="*70)
            logger.info("SUMMARY")
            logger.info("="*70)
            openwakeword_ms = results.get('openwakeword_ms', 0)
            whisper_ms = results.get('whisper_ms', 0)
            ollama_ms = results.get('ollama_ms', 0)
            piper_ms = results.get('piper_ms', 0)
            total_ms = results['total_ms']
            
            logger.info(f"Openwakeword:  {openwakeword_ms:8.2f}ms ({openwakeword_ms/1000:6.3f}s)")
            logger.info(f"Whisper:       {whisper_ms:8.2f}ms ({whisper_ms/1000:6.3f}s)")
            logger.info(f"Ollama:        {ollama_ms:8.2f}ms ({ollama_ms/1000:6.3f}s)")
            logger.info(f"Piper:         {piper_ms:8.2f}ms ({piper_ms/1000:6.3f}s)")
            logger.info("-"*70)
            logger.info(f"TOTAL:         {total_ms:8.2f}ms ({total_ms/1000:6.3f}s)")
            logger.info("="*70)
            
            # Add seconds to results for easier consumption
            results['openwakeword_s'] = openwakeword_ms / 1000
            results['whisper_s'] = whisper_ms / 1000
            results['ollama_s'] = ollama_ms / 1000
            results['piper_s'] = piper_ms / 1000
            results['total_s'] = total_ms / 1000
            
            # Store results
            self.last_results = results
            
            # Determine success
            has_errors = any(key.endswith('_error') for key in results.keys())
            if has_errors:
                logger.warning("⚠️  Test completed with errors")
            else:
                logger.info("✓ Test completed successfully")
            
            return results
        
        def get_last_results(self) -> Optional[Dict[str, Any]]:
            """Get the results from the last test run"""
            return self.last_results
        
        def get_prometheus_metrics(self) -> str:
            """Generate Prometheus-compatible metrics"""
            if not self.last_results:
                return "# No metrics available\n"
            
            metrics = []
            # Milliseconds metrics
            metrics.append("# HELP voice_pipeline_latency_ms Latency in milliseconds for each pipeline stage")
            metrics.append("# TYPE voice_pipeline_latency_ms gauge")
            
            for key, value in self.last_results.items():
                if key.endswith('_ms'):
                    stage = key.replace('_ms', '')
                    metrics.append(f'voice_pipeline_latency_ms{{stage="{stage}"}} {value}')
            
            # Seconds metrics for easier consumption
            metrics.append("# HELP voice_pipeline_latency_seconds Latency in seconds for each pipeline stage")
            metrics.append("# TYPE voice_pipeline_latency_seconds gauge")
            
            for key, value in self.last_results.items():
                if key.endswith('_s'):
                    stage = key.replace('_s', '')
                    metrics.append(f'voice_pipeline_latency_seconds{{stage="{stage}"}} {value}')
            
            if 'audio_size' in self.last_results:
                metrics.append("# HELP voice_pipeline_audio_size_bytes Size of audio files in bytes")
                metrics.append("# TYPE voice_pipeline_audio_size_bytes gauge")
                metrics.append(f'voice_pipeline_audio_size_bytes{{type="input"}} {self.last_results["audio_size"]}')
            
            if 'audio_response_size' in self.last_results:
                metrics.append(f'voice_pipeline_audio_size_bytes{{type="output"}} {self.last_results["audio_response_size"]}')
            
            # Add connectivity metrics
            if 'connectivity' in self.last_results:
                metrics.append("# HELP voice_pipeline_connectivity_ms HTTP/TCP connectivity test latency in milliseconds")
                metrics.append("# TYPE voice_pipeline_connectivity_ms gauge")
                for service, data in self.last_results['connectivity'].items():
                    if 'latency_ms' in data:
                        metrics.append(f'voice_pipeline_connectivity_ms{{service="{service}"}} {data["latency_ms"]}')
            
            return "\n".join(metrics) + "\n"
