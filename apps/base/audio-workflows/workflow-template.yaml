apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: audio-processing-pipeline
  namespace: audio-workflows
spec:
  serviceAccountName: audio-workflow-runner
  entrypoint: audio-pipeline
  ttlStrategy:
    secondsAfterCompletion: 86400  # 24h retention

  activeDeadlineSeconds: 172800  # 48 hour max runtime (large files need time for splitting + transcription)

  imagePullSecrets:
  - name: dockerhub-registry

  # Shared storage via NFS CSI PVCs
  volumes:
  - name: compressed-audio
    persistentVolumeClaim:
      claimName: compressed-audio
  - name: transcriptions
    persistentVolumeClaim:
      claimName: transcriptions
  - name: publisher-script
    configMap:
      name: transcript-publisher-script
  - name: summarizer-script
    configMap:
      name: transcript-summarizer-script
  - name: diary-script
    configMap:
      name: daily-diary-script

  templates:
  # Main DAG orchestrating the pipeline
  - name: audio-pipeline
    dag:
      tasks:
      - name: compress
        template: audio-compressor

      - name: transcribe
        template: audio-transcriber
        dependencies: [compress]

      # Fan-out: these 3 run in parallel after transcription
      - name: publish
        template: transcript-publisher
        dependencies: [transcribe]

      - name: summarize
        template: transcript-summarizer
        dependencies: [transcribe]

      - name: diary
        template: daily-diary
        dependencies: [transcribe]

  # Step 1: Audio Compression (SFTP download + WAV->MP3)
  - name: audio-compressor
    retryStrategy:
      limit: 3
      backoff:
        duration: "1m"
        factor: 2
        maxDuration: "10m"
    container:
      image: lzetam/audio-compressor:latest
      imagePullPolicy: Always
      command: ["python", "-u", "-m", "src.main"]
      env:
      # SFTP Configuration
      - name: SFTP_HOST
        value: "sftp-server.sftp-server.svc.cluster.local"
      - name: SFTP_PORT
        value: "22"
      - name: SFTP_REMOTE_PATH
        value: "audio/Voice Recordings"
      - name: SFTP_USERNAME
        valueFrom:
          secretKeyRef:
            name: sftp-credentials
            key: username
      - name: SFTP_PASSWORD
        valueFrom:
          secretKeyRef:
            name: sftp-credentials
            key: password
      # Storage Backend Configuration
      - name: STORAGE_BACKEND
        value: "local"  # Use local NFS volume for workflow steps
      # SFTP upload not needed in workflow - files go to shared NFS volume
      # - name: SFTP_DEST_PATH
      #   value: "compressed"
      # - name: UPLOAD_RETRY_ATTEMPTS
      #   value: "3"
      # - name: UPLOAD_RETRY_DELAY
      #   value: "5"
      # AWS Configuration
      - name: AWS_DEFAULT_REGION
        value: "us-east-1"
      - name: SFTP_SECRETS_NAME
        value: "sftp-server/credentials"
      # Storage Configuration
      - name: OUTPUT_DIR
        value: "/data"  # Volume mounted at /data, save to root
      - name: KEEP_ORIGINALS
        value: "false"
      # Compression Configuration (optimized for speech)
      - name: SAMPLE_RATE
        value: "16000"
      - name: CHANNELS
        value: "1"
      - name: BITRATE
        value: "32k"
      - name: AUDIO_FORMAT
        value: "mp3"
      # Processing Configuration
      - name: PROCESSING_MODE
        value: "flat"  # Flat file mode for .m4a files
      - name: FILE_EXTENSION
        value: ".m4a"  # File extension to process
      # Directory mode variables (not used in flat mode)
      # - name: AUDIO_FILENAME
      #   value: "StereoMix.wav"
      # - name: DIR_PATTERN
      #   value: "^\\d{2}-\\d{2}-\\d{2}(-\\d{2})?$"
      - name: METADATA_FILENAME
        value: "Meta.xml"
      - name: COPY_METADATA
        value: "false"  # No metadata files in flat mode
      - name: SKIP_PROCESSED
        value: "true"  # Skip already processed files (don't reprocess 2025 files)
      - name: MAX_FILE_SIZE_MB
        value: "100000"
      - name: MAX_RETRIES
        value: "3"
      - name: RETRY_DELAY
        value: "5"
      - name: LOG_LEVEL
        value: "INFO"
      - name: TEMP_DIR
        value: "/tmp/audio-processing"
      volumeMounts:
      - name: compressed-audio
        mountPath: /data
      resources:
        requests:
          memory: "512Mi"
          cpu: "500m"
        limits:
          memory: "2Gi"
          cpu: "2000m"

  # Step 2: Audio Transcription (Whisper)
  - name: audio-transcriber
    retryStrategy:
      limit: 3
      backoff:
        duration: "2m"
        factor: 2
        maxDuration: "45m"
    container:
      image: lzetam/audio-transcriber:latest
      imagePullPolicy: Always
      command: ["python", "-m", "src.main"]
      envFrom:
      - configMapRef:
          name: audio-transcriber-config
      env:
      - name: WHISPER_API_TYPE
        value: "whisperx"
      - name: WHISPER_BASE_URL
        value: "http://whisperx-api.whisperx.svc.cluster.local:8000"
      - name: WHISPER_API_KEY
        value: "not-required"
      - name: WHISPERX_ALIGN
        value: "true"
      - name: WHISPERX_DIARIZE
        value: "true"
      volumeMounts:
      - name: compressed-audio
        mountPath: /data/compressed
        readOnly: true
      - name: transcriptions
        mountPath: /data/transcriptions
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "1Gi"
          cpu: "500m"

  # Step 3a: Transcript Publisher (parallel)
  - name: transcript-publisher
    retryStrategy:
      limit: 3
      backoff:
        duration: "30s"
        factor: 2
    container:
      image: python:3.11-slim
      command: ["python", "/scripts/publisher.py"]
      envFrom:
      - configMapRef:
          name: transcript-publisher-config
      env:
      - name: OBSIDIAN_API_URL
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_url
      - name: OBSIDIAN_API_KEY
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_key
      - name: USE_TIMESTAMP_FILTER
        value: "false"  # Rely on SKIP_PROCESSED for idempotency
      volumeMounts:
      - name: publisher-script
        mountPath: /scripts
      - name: transcriptions
        mountPath: /data/transcriptions
        readOnly: true
      resources:
        requests:
          memory: "128Mi"
          cpu: "50m"
        limits:
          memory: "256Mi"
          cpu: "200m"

  # Step 3b: Transcript Summarizer (parallel)
  - name: transcript-summarizer
    retryStrategy:
      limit: 3
      backoff:
        duration: "30s"
        factor: 2
    container:
      image: python:3.11-slim
      command: ["python", "/scripts/summarizer.py"]
      envFrom:
      - configMapRef:
          name: transcript-summarizer-config
      env:
      - name: OBSIDIAN_API_URL
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_url
      - name: OBSIDIAN_API_KEY
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_key
      - name: SUMMARIZER_BASE_URL
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_base_url
      - name: SUMMARIZER_API_KEY
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_api_key
      - name: SUMMARIZER_MODEL
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_model
      - name: USE_TIMESTAMP_FILTER
        value: "true"
      - name: WORKFLOW_START_TIME
        value: "{{workflow.creationTimestamp}}"
      volumeMounts:
      - name: summarizer-script
        mountPath: /scripts
      - name: transcriptions
        mountPath: /data/transcriptions
        readOnly: true
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "1Gi"
          cpu: "500m"

  # Step 3c: Daily Diary (parallel)
  - name: daily-diary
    retryStrategy:
      limit: 3
      backoff:
        duration: "30s"
        factor: 2
    container:
      image: python:3.11-slim
      command: ["python", "/scripts/daily-diary.py"]
      envFrom:
      - configMapRef:
          name: daily-diary-config
      env:
      - name: OBSIDIAN_API_URL
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_url
      - name: OBSIDIAN_API_KEY
        valueFrom:
          secretKeyRef:
            name: obsidian-api
            key: api_key
      - name: SUMMARIZER_BASE_URL
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_base_url
      - name: SUMMARIZER_API_KEY
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_api_key
      - name: SUMMARIZER_MODEL
        valueFrom:
          secretKeyRef:
            name: summarizer-credentials
            key: summarizer_model
      - name: USE_TIMESTAMP_FILTER
        value: "true"
      - name: WORKFLOW_START_TIME
        value: "{{workflow.creationTimestamp}}"
      volumeMounts:
      - name: diary-script
        mountPath: /scripts
      - name: transcriptions
        mountPath: /data/transcriptions
        readOnly: true
      resources:
        requests:
          memory: "128Mi"
          cpu: "50m"
        limits:
          memory: "512Mi"
          cpu: "200m"
