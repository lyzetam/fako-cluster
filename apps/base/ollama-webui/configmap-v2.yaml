apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-webui-configmap
  namespace: ollama-webui
data:
  # Disable Ollama API completely
  ENABLE_OLLAMA_API: "false"
  OLLAMA_BASE_URL: ""
  OLLAMA_API_BASE_URL: ""
  
  # Enable OpenAI API mode
  ENABLE_OPENAI_API: "true"
  # These will be injected from secrets via init container
  OPENAI_API_BASE_URL: "${GPUSTACK_API_URL}"
  OPENAI_API_KEY: "${GPUSTACK_API_KEY}"
  OPENAI_API_BASE_URLS: "${GPUSTACK_API_URL}"
  OPENAI_API_KEYS: "${GPUSTACK_API_KEY}"
  
  # Other settings remain the same...
  WEBUI_NAME: "HomeLab AI (GPUStack)"
  DEFAULT_MODELS: "gemma-3-27b-it,glm4-0414"
  MODEL_FILTER_ENABLED: "false"
  BYPASS_MODEL_ACCESS_CONTROL: "true"
  
  # Alternative: Configure granular workspace permissions (use instead of BYPASS if you want more control)
  # USER_PERMISSIONS_WORKSPACE_MODELS_ACCESS: "true"
  # USER_PERMISSIONS_WORKSPACE_MODELS_CREATE: "false"  # Prevent users from creating custom models
  
  # Authentication settings
  WEBUI_AUTH: "true"
  ENABLE_SIGNUP: "true"
  DEFAULT_USER_ROLE: "user"
  WEBUI_SESSION_LIFETIME: "2592000"
  
  # User permissions
  USER_PERMISSIONS_CHAT_DELETION: "true"
  ENABLE_COMMUNITY_SHARING: "false"
  
  # Disable features that don't work with OpenAI API
  ENABLE_IMAGE_GENERATION: "false"
  ENABLE_RAG_WEB_SEARCH: "false"
  
  # Logging - Consider DEBUG for troubleshooting
  WEBUI_LOG_LEVEL: "INFO"
  # WEBUI_LOG_LEVEL: "DEBUG"  # Uncomment for detailed troubleshooting
  
  # Additional settings for better GPUStack integration
  ENABLE_OPENAI_COMPATIBLE_TITLE_GENERATION: "true"
  OPENAI_REQUEST_TIMEOUT: "600"  # 10 minutes for large model responses