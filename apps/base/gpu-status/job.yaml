# apps/base/gpu-status/job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-plugin-status
  namespace: gpu-status
spec:
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      serviceAccountName: gpu-status-checker
      restartPolicy: Never
      containers:
      - name: status-checker
        image: bitnami/kubectl:latest
        command:
        - /bin/bash
        - -c
        - |
          echo "=== GPU Device Plugin Status Check ==="
          echo "Date: $(date)"
          echo ""
          
          echo "=== Checking Node Labels ==="
          kubectl get nodes pgbee --show-labels || echo "Node pgbee not found"
          echo ""
          
          echo "=== Node Resource Capacity ==="
          kubectl describe node pgbee | grep -A 10 "Capacity:" || echo "Could not get node capacity"
          echo ""
          
          echo "=== Node Allocatable Resources ==="
          kubectl describe node pgbee | grep -A 10 "Allocatable:" || echo "Could not get allocatable resources"
          echo ""
          
          echo "=== GPU Device Plugin DaemonSet Status ==="
          kubectl get daemonset -n gpu-system amd-gpu-device-plugin -o wide || echo "Device plugin daemonset not found"
          echo ""
          
          echo "=== GPU Device Plugin Pods ==="
          kubectl get pods -n gpu-system -l name=amd-gpu-device-plugin -o wide || echo "No device plugin pods found"
          echo ""
          
          echo "=== GPU Device Plugin Pod Logs (last 50 lines) ==="
          POD=$(kubectl get pods -n gpu-system -l name=amd-gpu-device-plugin -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
          if [ ! -z "$POD" ]; then
            kubectl logs -n gpu-system $POD --tail=50 || echo "Could not get pod logs"
          else
            echo "No device plugin pod found to get logs from"
          fi
          echo ""
          
          echo "=== Events related to GPU ==="
          kubectl get events -A --field-selector reason=FailedScheduling | grep -i gpu || echo "No GPU scheduling failures found"
          echo ""
          
          echo "=== All Pods using GPU resources ==="
          kubectl get pods -A -o json | jq -r '.items[] | select(.spec.containers[].resources.limits."amd.com/gpu" or .spec.containers[].resources.requests."amd.com/gpu") | "\(.metadata.namespace)/\(.metadata.name)"' || echo "No pods requesting GPU resources"
          echo ""
          
          echo "=== Status Check Complete ==="