# apps/base/ollama/cleanup-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-cleanup-config
  namespace: ollama
data:
  models-to-delete.txt: |
    # Models to delete - one per line
    # Lines starting with # are ignored
    
    # GEMMA 2 MODELS
    gemma2:2b
    gemma2:9b
    
    # SMALL EFFICIENT MODELS
    llama3.2:3b
    phi3:mini
    
    # MEDIUM MODELS (7-8B)
    llama3.1:8b
    mistral:7b-instruct-v0.3-q5_K_M
    qwen2.5:7b-instruct-q5_K_M
    
    # LARGER MODELS (13B+)
    llama2:13b-chat-q4_K_M
    deepseek-r1:14b
    
    # HIGH-END MODELS
    mixtral:8x7b-instruct-v0.1-q3_K_M
    llama3.3:latest
    
  cleanup-script.sh: |
    #!/bin/sh
    set -e
    
    echo "=== Direct Model Cleanup Script (No Ollama Server Required) ==="
    echo "Starting at: $(date)"
    echo ""
    
    # Check if we're dealing with disk pressure
    echo "=== Checking node disk status ==="
    df -h
    echo ""
    
    # Show current state
    echo "=== Disk usage before cleanup ==="
    df -h /root/.ollama 2>/dev/null || echo "Ollama directory not mounted"
    echo ""
    
    # Check Ollama directory structure
    OLLAMA_DIR="/root/.ollama"
    MODELS_DIR="$OLLAMA_DIR/models"
    MANIFESTS_DIR="$MODELS_DIR/manifests"
    BLOBS_DIR="$MODELS_DIR/blobs"
    
    if [ ! -d "$OLLAMA_DIR" ]; then
        echo "ERROR: Ollama directory not found at $OLLAMA_DIR"
        echo "Checking alternative locations..."
        find / -name ".ollama" -type d 2>/dev/null | head -5
        exit 1
    fi
    
    echo "=== Model storage details ==="
    echo "Total Ollama directory size:"
    du -sh "$OLLAMA_DIR" 2>/dev/null || echo "Cannot calculate"
    echo ""
    echo "Subdirectory sizes:"
    du -sh "$OLLAMA_DIR"/* 2>/dev/null | sort -h || echo "No subdirectories found"
    echo ""
    
    # List all models by checking manifests
    echo "=== Current models (from manifests) ==="
    if [ -d "$MANIFESTS_DIR" ]; then
        find "$MANIFESTS_DIR" -type f -name "*.json" | while read manifest; do
            model_name=$(echo "$manifest" | sed "s|$MANIFESTS_DIR/||" | sed 's|/|:|g' | sed 's/.json$//')
            echo "  - $model_name"
        done
    else
        echo "No manifests directory found"
    fi
    echo ""
    
    # Read models to delete
    echo "=== Reading models to delete from config ==="
    MODELS_FILE="/config/models-to-delete.txt"
    
    if [ ! -f "$MODELS_FILE" ]; then
        echo "ERROR: Models file not found at $MODELS_FILE"
        exit 1
    fi
    
    # Process each model - direct file deletion
    echo "=== Starting direct deletion process ==="
    deleted_count=0
    while IFS= read -r model || [ -n "$model" ]; do
        # Skip empty lines and comments
        if [ -z "$model" ] || echo "$model" | grep -q '^#'; then
            continue
        fi
        
        # Trim whitespace
        model=$(echo "$model" | xargs)
        
        echo "Processing model: $model"
        
        # Convert model name to path format
        model_path=$(echo "$model" | sed 's|:|/|g')
        
        # Delete manifest
        manifest_file="$MANIFESTS_DIR/$model_path.json"
        if [ -f "$manifest_file" ]; then
            echo "  Deleting manifest: $manifest_file"
            rm -f "$manifest_file"
            deleted_count=$((deleted_count + 1))
            
            # Try to clean up empty directories
            manifest_dir=$(dirname "$manifest_file")
            rmdir "$manifest_dir" 2>/dev/null || true
            rmdir "$(dirname "$manifest_dir")" 2>/dev/null || true
        else
            echo "  Manifest not found: $manifest_file"
        fi
    done < "$MODELS_FILE"
    
    echo ""
    echo "Deleted $deleted_count model manifests"
    echo ""
    
    # Clean up orphaned blobs
    echo "=== Cleaning all blobs (aggressive cleanup due to disk pressure) ==="
    if [ -d "$BLOBS_DIR" ]; then
        blob_count=$(find "$BLOBS_DIR" -type f | wc -l)
        blob_size=$(du -sh "$BLOBS_DIR" 2>/dev/null | cut -f1)
        echo "Found $blob_count blob files totaling $blob_size"
        
        # Since we can't run ollama to check which blobs are in use,
        # we'll delete ALL blobs for maximum space recovery
        echo "Deleting ALL blob files..."
        rm -rf "$BLOBS_DIR"/*
        
        echo "All blobs deleted"
    else
        echo "No blobs directory found"
    fi
    
    # Clean up any temporary files
    echo ""
    echo "=== Cleaning temporary files ==="
    find "$OLLAMA_DIR" -name "*.tmp" -o -name "*.partial" | while read tmpfile; do
        echo "  Removing: $tmpfile"
        rm -f "$tmpfile"
    done
    
    echo ""
    echo "=== Cleanup complete ==="
    echo ""
    echo "=== Final disk usage ==="
    df -h /root/.ollama 2>/dev/null || echo "Ollama directory not mounted"
    echo ""
    echo "=== Remaining space ==="
    df -h
    echo ""
    echo "Completed at: $(date)"
---
# apps/base/ollama/cleanup-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: ollama-model-cleanup
  namespace: ollama
spec:
  template:
    spec:
      nodeSelector:
        kubernetes.io/hostname: yeezyai
      tolerations:
      - key: node.kubernetes.io/disk-pressure
        operator: Exists
        effect: NoSchedule
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      containers:
      - name: cleanup
        image: ollama/ollama:latest
        command: ["/bin/sh", "/config/cleanup-script.sh"]
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        volumeMounts:
        - name: ollama-models
          mountPath: /root/.ollama
        - name: cleanup-config
          mountPath: /config
          readOnly: true
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
      restartPolicy: Never
      volumes:
      - name: ollama-models
        persistentVolumeClaim:
          claimName: ollama-models
      - name: cleanup-config
        configMap:
          name: ollama-cleanup-config
          defaultMode: 0755  # Make script executable
  backoffLimit: 1
  ttlSecondsAfterFinished: 300  # Auto-delete job after 5 minutes
---
# apps/base/ollama/cleanup-cronjob.yaml (Optional - for scheduled cleanup)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ollama-model-cleanup-cron
  namespace: ollama
spec:
  schedule: "0 2 * * 0"  # Run at 2 AM every Sunday
  jobTemplate:
    spec:
      template:
        spec:
          nodeSelector:
            kubernetes.io/hostname: yeezyai
          tolerations:
          - key: node.kubernetes.io/disk-pressure
            operator: Exists
            effect: NoSchedule
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule
          containers:
          - name: cleanup
            image: ollama/ollama:latest
            command: ["/bin/sh", "/config/cleanup-script.sh"]
            env:
            - name: OLLAMA_HOST
              value: "0.0.0.0"
            volumeMounts:
            - name: ollama-models
              mountPath: /root/.ollama
            - name: cleanup-config
              mountPath: /config
              readOnly: true
            resources:
              requests:
                memory: "512Mi"
                cpu: "500m"
              limits:
                memory: "1Gi"
                cpu: "1000m"
          restartPolicy: Never
          volumes:
          - name: ollama-models
            persistentVolumeClaim:
              claimName: ollama-models
          - name: cleanup-config
            configMap:
              name: ollama-cleanup-config
              defaultMode: 0755
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1