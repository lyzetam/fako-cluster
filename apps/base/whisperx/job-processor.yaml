apiVersion: batch/v1
kind: Job
metadata:
  name: whisperx-processor
  namespace: whisperx
spec:
  backoffLimit: 1
  ttlSecondsAfterFinished: 86400  # Clean up after 24 hours
  template:
    spec:
      restartPolicy: Never
      runtimeClassName: nvidia
      hostIPC: true
      nodeSelector:
        kubernetes.io/hostname: aitower
        nvidia.com/gpu.present: "true"
      tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Exists
      imagePullSecrets:
      - name: dockerhub-registry
      initContainers:
      - name: install-whisperx
        image: python:3.11-slim
        command:
        - /bin/bash
        - -c
        - |
          echo "Installing WhisperX and dependencies..."
          apt-get update && apt-get install -y ffmpeg git
          pip install --target=/packages whisperx torch torchaudio
          echo "Installation complete. Packages:"
          ls -la /packages/
        volumeMounts:
        - name: packages
          mountPath: /packages
      containers:
      - name: whisperx
        image: nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
        command:
        - /bin/bash
        - -c
        - |
          echo "Setting up Python environment..."
          apt-get update && apt-get install -y python3 python3-pip ffmpeg
          export PYTHONPATH=/packages:$PYTHONPATH
          echo "Running WhisperX processor..."
          python3 /scripts/process.py
        env:
        - name: INPUT_DIR
          value: "/data/compressed"
        - name: OUTPUT_DIR
          value: "/data/output/whisperx"
        - name: WHISPER_MODEL
          value: "large-v2"
        - name: LANGUAGE
          value: "en"
        - name: BATCH_SIZE
          value: "16"
        - name: COMPUTE_TYPE
          value: "float16"
        - name: MAX_FILES
          value: "5"
        - name: SKIP_PROCESSED
          value: "true"
        - name: LOG_LEVEL
          value: "INFO"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: token
              optional: true
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "12Gi"
          requests:
            memory: "6Gi"
            cpu: "2"
        volumeMounts:
        - name: compressed-audio
          mountPath: /data/compressed
          readOnly: true
        - name: output
          mountPath: /data/output
        - name: script
          mountPath: /scripts
        - name: huggingface-cache
          mountPath: /root/.cache/huggingface
        - name: packages
          mountPath: /packages
      volumes:
      - name: compressed-audio
        nfs:
          server: ugnas.landryzetam.net
          path: /volume1/k8s-storage/pvc-fa625048-6545-4904-bc35-7111a93b21bc
      - name: output
        nfs:
          server: ugnas.landryzetam.net
          path: /volume1/k8s-storage/pvc-1a863515-490c-4c4a-8aaa-f63ce16b8ecc
      - name: script
        configMap:
          name: whisperx-processor-script
          defaultMode: 0755
      - name: huggingface-cache
        emptyDir: {}
      - name: packages
        emptyDir: {}
