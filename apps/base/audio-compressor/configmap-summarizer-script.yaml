apiVersion: v1
kind: ConfigMap
metadata:
  name: transcript-summarizer-script
  namespace: audio-compressor
data:
  summarizer.py: |
    #!/usr/bin/env python3
    """
    Transcript Summarizer - Summarizes transcripts using LLM and posts to Obsidian
    """
    import os
    import json
    import logging
    import textwrap
    import ssl
    import urllib.request
    import urllib.error
    from pathlib import Path
    from datetime import datetime
    import time

    # Create SSL context that doesn't verify certificates (for self-signed certs)
    SSL_CONTEXT = ssl.create_default_context()
    SSL_CONTEXT.check_hostname = False
    SSL_CONTEXT.verify_mode = ssl.CERT_NONE

    # Configuration from environment
    INPUT_DIR = os.environ.get('INPUT_DIR', '/data/transcriptions')
    STATE_DIR = os.environ.get('STATE_DIR', '/data/state')
    OBSIDIAN_FOLDER = os.environ.get('OBSIDIAN_FOLDER', 'Transcripts')
    OBSIDIAN_API_URL = os.environ['OBSIDIAN_API_URL']
    OBSIDIAN_API_KEY = os.environ['OBSIDIAN_API_KEY']
    SUMMARIZER_BASE_URL = os.environ['SUMMARIZER_BASE_URL']
    SUMMARIZER_API_KEY = os.environ['SUMMARIZER_API_KEY']
    SUMMARIZER_MODEL = os.environ.get('SUMMARIZER_MODEL', 'gemma3')
    SKIP_PROCESSED = os.environ.get('SKIP_PROCESSED', 'true').lower() == 'true'
    MAX_RETRIES = int(os.environ.get('MAX_RETRIES', '3'))
    RETRY_DELAY = int(os.environ.get('RETRY_DELAY', '10'))
    LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')

    SUMMARY_PROMPT = os.environ.get('SUMMARY_PROMPT', textwrap.dedent("""\
        You are analyzing an audio transcript. Provide a concise summary that includes:

        1. **Main Topics**: List the key subjects discussed
        2. **Summary**: A brief overview of the content (2-3 paragraphs)
        3. **Key Points**: Important facts, decisions, or insights
        4. **Action Items**: Any tasks or follow-ups mentioned (if applicable)

        Be concise but comprehensive. Format your response in markdown.
        """))

    logging.basicConfig(level=getattr(logging, LOG_LEVEL),
                        format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    STATE_FILE = Path(STATE_DIR) / 'summarizer-processed.txt'

    def load_processed():
        if STATE_FILE.exists():
            return set(STATE_FILE.read_text().strip().split('\n'))
        return set()

    def save_processed(processed):
        STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        STATE_FILE.write_text('\n'.join(sorted(processed)))

    def call_llm(transcript_text):
        """Call GPUStack/OpenAI-compatible API to summarize transcript."""
        url = f"{SUMMARIZER_BASE_URL}/chat/completions"
        headers = {
            'Authorization': f'Bearer {SUMMARIZER_API_KEY}',
            'Content-Type': 'application/json'
        }

        payload = {
            "model": SUMMARIZER_MODEL,
            "messages": [
                {"role": "system", "content": SUMMARY_PROMPT},
                {"role": "user", "content": f"Please summarize this transcript:\n\n{transcript_text}"}
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }

        for attempt in range(MAX_RETRIES):
            try:
                data = json.dumps(payload).encode('utf-8')
                req = urllib.request.Request(url, data=data, headers=headers, method='POST')
                with urllib.request.urlopen(req, timeout=120) as response:
                    result = json.loads(response.read().decode('utf-8'))
                    return result['choices'][0]['message']['content']
            except urllib.error.HTTPError as e:
                error_body = e.read().decode('utf-8') if e.fp else ''
                logger.warning(f"LLM API returned {e.code}: {e.reason} - {error_body}")
            except Exception as e:
                logger.error(f"LLM attempt {attempt+1} failed: {e}")

            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)

        return None

    def create_summary_markdown(filename, transcript_data, summary):
        """Create markdown document with summary and metadata."""
        text = transcript_data.get('text', '')
        duration = transcript_data.get('duration', 0)
        language = transcript_data.get('language', 'unknown')

        # Format duration
        mins, secs = divmod(int(duration), 60)
        hours, mins = divmod(mins, 60)
        duration_str = f"{hours}h {mins}m {secs}s" if hours else f"{mins}m {secs}s"

        md = textwrap.dedent(f"""\
            # Summary: {filename}

            **Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
            **Duration**: {duration_str}
            **Language**: {language}
            **Model**: {SUMMARIZER_MODEL}

            ---

            {summary}

            ---

            ## Original Transcript

            <details>
            <summary>Click to expand full transcript</summary>

            {text}

            </details>

            ---

            *Generated by transcript-summarizer*
            """)
        return md

    def post_to_obsidian(filename, content):
        """Post markdown content to Obsidian REST API."""
        url = f"{OBSIDIAN_API_URL}/vault/{OBSIDIAN_FOLDER}/{filename}"
        headers = {
            'Authorization': f'Bearer {OBSIDIAN_API_KEY}',
            'Content-Type': 'text/markdown'
        }

        for attempt in range(MAX_RETRIES):
            try:
                req = urllib.request.Request(url, data=content.encode('utf-8'), headers=headers, method='PUT')
                with urllib.request.urlopen(req, context=SSL_CONTEXT) as response:
                    if response.status in (200, 201, 204):
                        logger.info(f"Posted {filename} to Obsidian")
                        return True
                    logger.warning(f"Obsidian API returned {response.status}")
            except urllib.error.HTTPError as e:
                logger.warning(f"Obsidian API returned {e.code}: {e.reason}")
            except Exception as e:
                logger.error(f"Obsidian attempt {attempt+1} failed: {e}")

            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)

        return False

    def main():
        logger.info("Starting transcript summarizer")
        logger.info(f"Input: {INPUT_DIR}, Output: {OBSIDIAN_FOLDER}")
        logger.info(f"Using model: {SUMMARIZER_MODEL} at {SUMMARIZER_BASE_URL}")

        processed = load_processed() if SKIP_PROCESSED else set()
        input_path = Path(INPUT_DIR)

        json_files = list(input_path.glob('*.json'))
        logger.info(f"Found {len(json_files)} JSON files")

        success_count = 0
        for json_file in json_files:
            if json_file.name in processed:
                logger.debug(f"Skipping already processed: {json_file.name}")
                continue

            try:
                logger.info(f"Processing: {json_file.name}")
                data = json.loads(json_file.read_text())
                transcript_text = data.get('text', '')

                if not transcript_text:
                    logger.warning(f"Empty transcript in {json_file.name}")
                    continue

                # Get summary from LLM
                summary = call_llm(transcript_text)
                if not summary:
                    logger.error(f"Failed to get summary for {json_file.name}")
                    continue

                # Create markdown and post to Obsidian
                md_content = create_summary_markdown(json_file.stem, data, summary)
                md_filename = f"{json_file.stem}.md"

                if post_to_obsidian(md_filename, md_content):
                    processed.add(json_file.name)
                    success_count += 1
                    logger.info(f"Successfully summarized and posted: {json_file.name}")

            except Exception as e:
                logger.error(f"Failed to process {json_file.name}: {e}")

        save_processed(processed)
        logger.info(f"Summarized {success_count} transcripts to Obsidian")

    if __name__ == '__main__':
        main()
