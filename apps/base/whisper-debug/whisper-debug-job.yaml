# apps/base/whisper-debug/whisper-debug-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: whisper-debug
  namespace: cleanup-jobs
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      serviceAccountName: cleanup-admin
      restartPolicy: Never
      containers:
      - name: debug
        image: bitnami/kubectl:latest
        command:
        - /bin/bash
        - -c
        - |
          echo "=== Whisper GPU Debug Report ==="
          echo "Date: $(date)"
          echo ""
          
          # 1. Check why whisper pods are pending
          echo "1. Whisper Pod Events:"
          echo "======================"
          kubectl get events -n whisper --sort-by='.lastTimestamp' | tail -20
          echo ""
          
          # 2. Describe pending pods
          echo "2. Pending Pod Details:"
          echo "======================="
          for pod in $(kubectl get pods -n whisper --field-selector=status.phase=Pending -o name); do
            echo "Pod: $pod"
            kubectl describe $pod -n whisper | grep -A20 "Events:"
            echo "---"
          done
          
          # 3. Check node scheduling issues
          echo ""
          echo "3. Node Scheduling Conditions:"
          echo "=============================="
          kubectl describe node playground | grep -A10 "Conditions:"
          echo ""
          
          # 4. Check if RuntimeClass exists
          echo "4. RuntimeClass Check:"
          echo "====================="
          kubectl get runtimeclass nvidia -o yaml 2>/dev/null || echo "RuntimeClass 'nvidia' not found!"
          echo ""
          
          # 5. Check if GPU is actually available
          echo "5. GPU Availability on Node:"
          echo "==========================="
          kubectl get node playground -o json | jq '.status.allocatable | to_entries[] | select(.key | contains("gpu"))'
          echo ""
          
          # 6. Check taints and tolerations
          echo "6. Node Taints:"
          echo "==============="
          kubectl get node playground -o json | jq '.spec.taints'
          echo ""
          
          # 7. Check NVIDIA driver on node
          echo "7. NVIDIA Driver Check (from device plugin logs):"
          echo "================================================="
          kubectl logs -n nvidia-device-plugin -l name=nvidia-device-plugin-ds --tail=50 | grep -E "(driver|nvidia-smi|GPU)" || echo "No relevant logs"
          echo ""
          
          # 8. List all GPU-related pods
          echo "8. All GPU-Related Pods:"
          echo "========================"
          kubectl get pods -A | grep -E "(nvidia|gpu|whisper)"
          echo ""
          
          echo "=== Debug Report Complete ==="