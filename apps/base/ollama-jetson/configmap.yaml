apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-configmap
  namespace: ollama-jetson
data:
  OLLAMA_HOST: "0.0.0.0"
  OLLAMA_ORIGINS: "*"
  OLLAMA_MODELS: "/root/.ollama/models"
  OLLAMA_DEBUG: "false"
  OLLAMA_NOHISTORY: "false"  # Keep conversation history
  
  # ARM-specific optimizations for Jetson
  GOARCH: "arm64"
  GOOS: "linux"
---
# Separate ConfigMap for GPU-specific settings (Jetson Orin Nano)
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-gpu-configmap
  namespace: ollama-jetson
data:
  # GPU Configuration for Jetson
  CUDA_VISIBLE_DEVICES: "0"
  NVIDIA_VISIBLE_DEVICES: "0"
  NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
  
  # Ollama GPU Settings - optimized for Jetson Orin Nano
  OLLAMA_GPU_LAYERS: "999"  # Force all layers to GPU
  OLLAMA_CUDA_FORCE_MMQ: "1"
  OLLAMA_FLASH_ATTENTION: "0"  # Disabled - not supported
  OLLAMA_GPU_MEMORY: "6G"  # Conservative for 8GB system
  
  # Performance Settings - adjusted for ARM Cortex-A78AE
  OLLAMA_NUM_PARALLEL: "1"  # Conservative for Jetson
  OLLAMA_NUM_THREAD: "6"    # 6-core CPU
  OLLAMA_MAX_LOADED_MODELS: "1"  # Keep one model loaded
  GOMAXPROCS: "6"
  
  # Memory Management - optimized for dedicated device
  OLLAMA_KEEP_ALIVE: "24h"  # Keep model loaded for 24 hours (essentially permanent)
  OLLAMA_NO_MMAP: "false"   # Keep memory mapping for efficiency
  
  # Force CUDA path
  OLLAMA_LLM_LIBRARY: "cublas"
  
  # Context and batch settings
  OLLAMA_CONTEXT_LENGTH: "4096"
  
  # GPU overhead - use all available VRAM since dedicated device
  OLLAMA_GPU_OVERHEAD: "0"
